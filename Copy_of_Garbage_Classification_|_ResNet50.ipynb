{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6704311,
          "sourceType": "datasetVersion",
          "datasetId": 3863975
        }
      ],
      "dockerImageVersionId": 30559,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansilpm/dffdd/blob/main/Copy_of_Garbage_Classification_%7C_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "farzadnekouei_trash_type_image_dataset_path = kagglehub.dataset_download('farzadnekouei/trash-type-image-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ajv2oBm6cicX"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/FarzadNekouee/Garbage_Classification_ResNet50_Scratch_to_Transfer-Learning/blob/master/images/Cover_Image_txt.png?raw=true\" width=\"2400\">"
      ],
      "metadata": {
        "id": "TtWq0FDrcicd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:130%; text-align:left\">\n",
        "\n",
        "<h1 align=\"left\"><font color=royalblue>Description: </font></h1>\n",
        "    \n",
        "In this project, we aim to develop a sophisticated garbage classification system leveraging the ResNet50 architecture. Our primary dataset serves as a foundation for building models that can eventually automate waste segregation, a critical step in optimizing recycling and waste management, ultimately aiding in environmental conservation. A notable challenge encountered is the inherent class imbalance within the dataset, prompting the exploration of data augmentation, and varied evaluation metrics. The project journey encompasses a comprehensive dataset analysis, addresses the imbalance, and delves deep into building and evaluating models both from scratch and through transfer learning with ResNet50."
      ],
      "metadata": {
        "id": "xDaRDVGfcicf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color: lavender; font-size:130%; text-align:left\">\n",
        "\n",
        "<h1 align=\"left\"><font color=royalblue>Objectives:</font></h1>\n",
        "    \n",
        "\n",
        "- **Dataset Exploration:** Dive into the garbage dataset, emphasizing class imbalances.\n",
        "- **Tackle Imbalance:** Utilize class weights in the loss function to address dataset disparities.\n",
        "- **Implement Data Augmentation:** Enhance model generalization and combat overfitting.\n",
        "- **Construct ResNet50:** Design a custom ResNet50 for garbage classification from scratch.\n",
        "- **Employ Transfer Learning:** Leverage a pre-trained ResNet50, adapting it for our specific dataset.\n",
        "- **Evaluate Models:** Assess both models' performance using varied metrics to ensure reliable classification.\n"
      ],
      "metadata": {
        "id": "NE2slmZqcicg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"contents_tabel\"></a>    \n",
        "<div style=\"border-radius:10px; padding: 15px; background-color: lavender; font-size:130%; text-align:left\">\n",
        "\n",
        "<h1 align=\"left\"><font color=royalblue>Table of Contents:</font></h1>\n",
        "    \n",
        "* [Step 1 | Setup and Initialization](#Initialization)\n",
        "* [Step 2 | Dataset Analysis](#Dataset_Analysis)\n",
        "* [Step 3 | Dataset Preparation](#Dataset_Preparation)\n",
        "    - [Step 3.1 | Centralize Dataset Information](#Centralize_Dataset)\n",
        "    - [Step 3.2 | Stratified Data Splitting: Train & Validation](#Splitting_Dataset)\n",
        "    - [Step 3.3 | Data Augmentation & Rescaling](#Data_Augmentation)\n",
        "    - [Step 3.4 | Generating Batches of Images](#Generate_Batch)\n",
        "* [Step 4 | Addressing Dataset Imbalances](#Dataset_Imbalances)\n",
        "* [Step 5 | ResNet50 Built from Scratch](#Resnet50)\n",
        "    - [Step 5.1 | Defining the ResNet50 Architecture from Scratch](#Define_Scratch)\n",
        "    - [Step 5.2 | Training the Defined ResNet50 Model](#Train_Scratch)\n",
        "    - [Step 5.3 | Evaluating the Defined ResNet50 Model](#Eval_Scratch)\n",
        "* [Step 6 | ResNet50 with Transfer Learning](#Transfer_Learning)\n",
        "    - [Step 6.1 | Loading ResNet50 with Pre-trained Weights](#Define_tf)\n",
        "    - [Step 6.2 | Applying ResNet50-specific Image Preprocessing](#Preprocess_tf)\n",
        "    - [Step 6.3 | Fine-tuning the Transfer Learning ResNet50 Model](#Train_tf)\n",
        "    - [Step 6.4 | Evaluating the Transfer Learning ResNet50 Model](#Eval_tf)"
      ],
      "metadata": {
        "id": "OaHJ0pH3cich"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align=\"left\"><font color=royalblue>Let's get started:</font></h2>"
      ],
      "metadata": {
        "id": "9hZqxRHXcich"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Initialization\"></a>\n",
        "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 1 | Setup and Initialization</p>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "Ny0tLtO0cici"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "First, I will bring in the libraries I need for this project:"
      ],
      "metadata": {
        "id": "A7BGhI5ncicj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Activation, Add, Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T14:06:46.077832Z",
          "iopub.execute_input": "2025-05-02T14:06:46.078125Z",
          "iopub.status.idle": "2025-05-02T14:06:46.084262Z",
          "shell.execute_reply.started": "2025-05-02T14:06:46.078101Z",
          "shell.execute_reply": "2025-05-02T14:06:46.083225Z"
        },
        "id": "T3nMDHxScick"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Dataset_Analysis\"></a>\n",
        "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 2 | Dataset Analysis</p>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "GTgC0xl-cicl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Now, I am going to take a look inside the different folders of the dataset containing different garbage types. For each garbage type, I will count its pictures and check if they all have the same size. Then, I will display these details for every garbage type:"
      ],
      "metadata": {
        "id": "XhZeCBAscicl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path where our dataset is stored\n",
        "dataset_path = r'/kaggle/input/trash-type-image-dataset'\n",
        "\n",
        "# Retrieve the names of all folders (representing trash types) within the dataset directory\n",
        "garbage_types = os.listdir(dataset_path)\n",
        "\n",
        "# Set to store unique image dimensions for the entire dataset\n",
        "all_dimensions_set = set()\n",
        "\n",
        "# Iterate over each trash type (folder) to process images\n",
        "for garbage_type in garbage_types:\n",
        "    folder_path = os.path.join(dataset_path, garbage_type)\n",
        "\n",
        "    # Verify that the current item is a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg'))]\n",
        "\n",
        "        # Display the count of images in the current folder\n",
        "        num_images = len(image_files)\n",
        "        print(f\"{garbage_type} folder contains {num_images} images.\")\n",
        "\n",
        "        # Loop over each image to check its dimensions\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            with Image.open(image_path) as img:\n",
        "                # Extract the width, height, and channels (color depth) of the image and add to the dimensions set\n",
        "                width, height = img.size\n",
        "                channels = len(img.getbands())\n",
        "                all_dimensions_set.add((width, height, channels))\n",
        "\n",
        "# Determine if all images in the entore dataset have the same dimensions\n",
        "if len(all_dimensions_set) == 1:\n",
        "    width, height, channel = all_dimensions_set.pop()\n",
        "    print(f\"\\nAll images in the dataset have the same dimensions: {width}x{height} with {channels} color channels.\")\n",
        "else:\n",
        "    print(\"\\nThe images in the dataset have different dimensions or color channels.\")"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T14:06:55.199988Z",
          "iopub.execute_input": "2025-05-02T14:06:55.200634Z",
          "iopub.status.idle": "2025-05-02T14:06:56.976604Z",
          "shell.execute_reply.started": "2025-05-02T14:06:55.200603Z",
          "shell.execute_reply": "2025-05-02T14:06:56.975696Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "iVW1_lR-cicm",
        "outputId": "066044e7-517a-498e-cd31-77458a820e2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/trash-type-image-dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-3734122520.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Retrieve the names of all folders (representing trash types) within the dataset directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgarbage_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Set to store unique image dimensions for the entire dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/trash-type-image-dataset'"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📊 Inference on Class Imbalance</font></h2>\n",
        "\n",
        "\n",
        "The \"Garbage Image Dataset\" reveals a noticeable imbalance in the distribution of its image categories:\n",
        "\n",
        "- **cardboard**: 403 images\n",
        "- **glass**: 501 images\n",
        "- **metal**: 410 images\n",
        "- **paper**: 594 images\n",
        "- **plastic**: 482 images\n",
        "- **trash**: 137 images\n",
        "\n",
        "Imagine teaching a child to identify animals by showing them 95 pictures of cats and just 5 pictures of dogs. They'd probably start to think most pets are cats due to the sheer number of cat images they've seen. Similarly, in our dataset, a machine learning model might become adept at identifying \"paper\" but may not be as skilled with \"trash\" because of the fewer examples.\n",
        "\n",
        "This can lead to:\n",
        "\n",
        "1️⃣ **Bias**: The model might lean towards predicting \"paper\" often because it's seen it more during training.\n",
        "    \n",
        "    \n",
        "2️⃣ **Generalization Issues**: If we deploy our model in a real-world scenario where \"trash\" items are just as common as \"paper\" items, our model might not perform well.\n",
        "\n",
        "    \n",
        "3️⃣ **Accuracy Deception**: The model could seem highly accurate if it keeps guessing the dominant class, but it might be weak in detecting underrepresented classes like \"trash\".\n",
        "\n",
        "To create an efficient classifier, addressing this imbalance is crucial."
      ],
      "metadata": {
        "id": "DnvCKB0vcicm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Let's visually explore the images from each garbage category:"
      ],
      "metadata": {
        "id": "JcxGvscIcicn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each trash type (folder) to display images\n",
        "for garbage_type in garbage_types:\n",
        "    folder_path = os.path.join(dataset_path, garbage_type)\n",
        "\n",
        "    # Verify that the current item is a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg'))]\n",
        "\n",
        "        # Select the first 10 images\n",
        "        image_files = image_files[:7]\n",
        "\n",
        "        # Set up subplots\n",
        "        fig, axs = plt.subplots(1, 7, figsize=(15, 2))\n",
        "\n",
        "        for i, image_file in enumerate(image_files):\n",
        "            image_path = os.path.join(folder_path, image_file)\n",
        "            with Image.open(image_path) as img:\n",
        "                axs[i].imshow(img)\n",
        "                axs[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        fig.suptitle(garbage_type, fontsize=20, y=1.03)\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:07:08.512456Z",
          "iopub.execute_input": "2025-05-02T14:07:08.513091Z",
          "iopub.status.idle": "2025-05-02T14:07:11.072176Z",
          "shell.execute_reply.started": "2025-05-02T14:07:08.513062Z",
          "shell.execute_reply": "2025-05-02T14:07:11.071302Z"
        },
        "trusted": true,
        "id": "0S9e0zkkcicn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Dataset_Preparation\"></a>\n",
        "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 3 | Dataset Preparation</p>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "MaDbS3DDcico"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Centralize_Dataset\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 3.1 |</span><span style='color:royalblue'> Centralize Dataset Information</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "VkoqodnWcico"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "### 🔍 <span style=\"color:royalblue\">Concern:</span>\n",
        "We have all our images scattered across multiple folders, one for each garbage class. We need a unified view of the data for easy manipulation.\n",
        "\n",
        "### 🛠️ <span style=\"color:royalblue\">Strategy:</span>\n",
        "Create a DataFrame that contains file paths and corresponding labels."
      ],
      "metadata": {
        "id": "mJg85_Orcicp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store image file paths and their respective labels\n",
        "data = []\n",
        "\n",
        "# Loop through each garbage type and collect its images' file paths\n",
        "for garbage_type in garbage_types:\n",
        "    for file in os.listdir(os.path.join(dataset_path, garbage_type)):\n",
        "        # Append the image file path and its trash type (as a label) to the data list\n",
        "        data.append((os.path.join(dataset_path, garbage_type, file), garbage_type))\n",
        "\n",
        "# Convert the collected data into a DataFrame\n",
        "df = pd.DataFrame(data, columns=['filepath', 'label'])\n",
        "\n",
        "# Display the first few entries of the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:07:19.790811Z",
          "iopub.execute_input": "2025-05-02T14:07:19.791128Z",
          "iopub.status.idle": "2025-05-02T14:07:19.810558Z",
          "shell.execute_reply.started": "2025-05-02T14:07:19.7911Z",
          "shell.execute_reply": "2025-05-02T14:07:19.809747Z"
        },
        "trusted": true,
        "id": "_2Ai7ygtcicp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Splitting_Dataset\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 3.2 |</span><span style='color:royalblue'> Stratified Data Splitting: Train & Validation</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "joX4fhtGcicq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "### 🔍 <span style=\"color:royalblue\">Concern:</span>\n",
        "To ensure our train and validation sets represent all garbage classes well, and to avoid potential biases associated with the order of images, we need the sets to have a similar distribution of classes as the whole dataset and also be shuffled.\n",
        "\n",
        "### 🛠️ <span style=\"color:royalblue\">Strategy:</span>\n",
        "Employ stratified sampling through `train_test_split`, which inherently shuffles and divides the DataFrame while maintaining a consistent distribution of classes."
      ],
      "metadata": {
        "id": "Txj8ODtUcicq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split with stratification\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Print the number of images in each set\n",
        "print(f\"Number of images in the training set: {len(train_df)}\")\n",
        "print(f\"Number of images in the validation set: {len(val_df)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:07:24.060815Z",
          "iopub.execute_input": "2025-05-02T14:07:24.06158Z",
          "iopub.status.idle": "2025-05-02T14:07:24.073464Z",
          "shell.execute_reply.started": "2025-05-02T14:07:24.061536Z",
          "shell.execute_reply": "2025-05-02T14:07:24.072501Z"
        },
        "trusted": true,
        "id": "jw0uqXKbcicq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Let's verify that the distributions in the training and validation sets closely mirror the overall distribution:"
      ],
      "metadata": {
        "id": "V4dkzF5Hcict"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Class distribution in the entire dataset\n",
        "overall_distribution = df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "# 2. Class distribution in the training set\n",
        "train_distribution = train_df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "# 3. Class distribution in the validation set\n",
        "val_distribution = val_df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"Class distribution in the entire dataset:\\n\")\n",
        "print(overall_distribution.round(2))\n",
        "print('-'*40)\n",
        "\n",
        "print(\"\\nClass distribution in the training set:\\n\")\n",
        "print(train_distribution.round(2))\n",
        "print('-'*40)\n",
        "\n",
        "print(\"\\nClass distribution in the validation set:\\n\")\n",
        "print(val_distribution.round(2))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:07:27.222341Z",
          "iopub.execute_input": "2025-05-02T14:07:27.223179Z",
          "iopub.status.idle": "2025-05-02T14:07:27.23377Z",
          "shell.execute_reply.started": "2025-05-02T14:07:27.223147Z",
          "shell.execute_reply": "2025-05-02T14:07:27.232879Z"
        },
        "trusted": true,
        "id": "yT5qmDqJcicu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📊 Inference on Stratification Effectiveness</font></h2>\n",
        "\n",
        "The class distributions in both the training and validation sets closely mirror the overall distribution in the entire dataset, indicating that stratification during the split was successful."
      ],
      "metadata": {
        "id": "Iom6CqaAcicv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Data_Augmentation\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 3.3 |</span><span style='color:royalblue'> Data Augmentation & Rescaling</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "JyDBYkJTcicv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "### 🔍 <span style=\"color:royalblue\">Concern:</span>\n",
        "- We have limited images, so we risk overfitting.\n",
        "- Neural networks work better with input values between 0 and 1, but our images have pixel values between 0 and 255.\n",
        "\n",
        "### 🛠️ <span style=\"color:royalblue\">Strategy:</span>\n",
        "- Augment the training images to artificially increase dataset size.\n",
        "- Rescale both training and validation images for better network performance."
      ],
      "metadata": {
        "id": "kep3sVBAcicv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📌 Note on Data Augmentation in Validation Set</font></h2>\n",
        "\n",
        "__Data augmentation__ is a technique primarily used to expand the training dataset in order to improve the model's capacity to generalize and avoid overfitting. The primary objective is to introduce variability and mimic potential real-world distortions in the training images without actually collecting more data.\n",
        "\n",
        "On the other hand, the validation set's role is to provide an unbiased evaluation of a model's performance on unseen data. Thus, we want the validation data to remain consistent throughout the model's training process to ensure that our evaluations are stable and reproducible. Applying augmentations to the validation set would introduce random variability in the evaluation metrics across different epochs, making it harder to determine whether changes in the model's performance are due to the model's learning or just the variability introduced by augmentations.\n",
        "\n",
        "Therefore, to maintain a consistent and clear evaluation benchmark, I refrain from applying data augmentation to the validation set, using only rescaling to ensure the pixel values are in a similar range as the augmented training images."
      ],
      "metadata": {
        "id": "82STilOCcicv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📌 Designing Data Augmentation for Trash Classification</font></h2>\n",
        "\n",
        "Based on the dataset, here are some observations regarding the potential data augmentation techniques:\n",
        "\n",
        "<h3 align=\"left\"><font color=royalblue>Suitable Transformations:</font></h3>\n",
        "\n",
        "- __Rescaling__: Necessary to normalize pixel values between 0 and 1.\n",
        "- __Rotation__: Captures objects in various orientations.\n",
        "- __Width and Height Shift__: Models minor positional changes.\n",
        "- __Zoom__: Simulates different object distances.\n",
        "- __Flip__: Captures different horizontal or vertical orientations.\n",
        "- __Shear__: Provides a skewed perspective of images.\n",
        "- __Brightness Adjustment__: Adapts images to diverse lighting conditions.\n",
        "- __Channel Shift__: Alters colors for added variety.\n",
        "- __Fill Mode__: Addresses missing pixel values."
      ],
      "metadata": {
        "id": "Ik7ebhvIcicw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slight Augmentation settings for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,                     # Normalize pixel values to [0,1]\n",
        "    rotation_range=45,                  # Randomly rotate the images by up to 45 degrees\n",
        "    width_shift_range=0.15,             # Randomly shift images horizontally by up to 15% of the width\n",
        "    height_shift_range=0.15,            # Randomly shift images vertically by up to 15% of the height\n",
        "    zoom_range=0.15,                    # Randomly zoom in or out by up to 15%\n",
        "    horizontal_flip=True,               # Randomly flip images horizontally\n",
        "    vertical_flip=True,                 # Randomly flip images vertically\n",
        "    shear_range=0.05,                   # Apply slight shear transformations\n",
        "    brightness_range=[0.9, 1.1],        # Vary brightness between 90% to 110% of original\n",
        "    channel_shift_range=10,             # Randomly shift channels (can change colors of images slightly but less aggressively)\n",
        "    fill_mode='nearest'                 # Fill in missing pixels using the nearest filled value\n",
        ")\n",
        "\n",
        "# Only rescaling for validation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:07:35.88761Z",
          "iopub.execute_input": "2025-05-02T14:07:35.888497Z",
          "iopub.status.idle": "2025-05-02T14:07:35.893457Z",
          "shell.execute_reply.started": "2025-05-02T14:07:35.88845Z",
          "shell.execute_reply": "2025-05-02T14:07:35.892587Z"
        },
        "trusted": true,
        "id": "1pIu81khcicw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Generate_Batch\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 3.4 |</span><span style='color:royalblue'> Generating Batches of Images</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "z9HKZys0cicx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "### 🔍 <span style=\"color:royalblue\">Concern:</span>\n",
        "- We can't load all images at once due to memory constraints.\n",
        "- We want to benefit from the DataFrame format to feed our images into our model.\n",
        "- Most CNN architectures often perform better with square images.\n",
        "- We aim to avoid manual one-hot encoding of labels.\n",
        "- Ensuring consistent ordering and reproducibility during training.\n",
        "\n",
        "### 🛠️ <span style=\"color:royalblue\">Strategy:</span>\n",
        "- Use the `flow_from_dataframe` method to generate batches of images and labels directly from our DataFrame.\n",
        "- Rescale images to 384x384 to maintain a square shape, aligning with the design preferences of CNNs.\n",
        "- Leverage the initial shuffling done through `train_test_split` to randomize data order, eliminating the need for additional shuffling in the generators.\n",
        "- Use a seed (`seed=0`) during data augmentation to ensure reproducibility of transformations across runs."
      ],
      "metadata": {
        "id": "0RVXW8zAcicx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using flow_from_dataframe to generate batches\n",
        "# Generate training batches from the training dataframe\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,                  # DataFrame containing training data\n",
        "    x_col=\"filepath\",                    # Column with paths to image files\n",
        "    y_col=\"label\",                       # Column with image labels\n",
        "    target_size=(384, 384),              # Resize all images to size of 384x384\n",
        "    batch_size=32,                       # Number of images per batch\n",
        "    class_mode='categorical',            # One-hot encode labels\n",
        "    seed=42,                             # Seed for random number generator to ensure reproducibility\n",
        "    shuffle=False                        # Data is not shuffled; order retained from DataFrame\n",
        ")\n",
        "\n",
        "\n",
        "# Generate validation batches from the validation dataframe\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,                    # DataFrame containing validation data\n",
        "    x_col=\"filepath\",                    # Column with paths to image files\n",
        "    y_col=\"label\",                       # Column with image labels\n",
        "    target_size=(384, 384),              # Resize all images to size of 384x384\n",
        "    batch_size=32,                       # Number of images per batch\n",
        "    class_mode='categorical',            # One-hot encode labels\n",
        "    seed=42,                             # Seed for random number generator to ensure reproducibility\n",
        "    shuffle=False                        # Data is not shuffled; order retained from DataFrame\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:06.362589Z",
          "iopub.execute_input": "2025-05-02T14:08:06.362896Z",
          "iopub.status.idle": "2025-05-02T14:08:07.778638Z",
          "shell.execute_reply.started": "2025-05-02T14:08:06.362873Z",
          "shell.execute_reply": "2025-05-02T14:08:07.777737Z"
        },
        "trusted": true,
        "id": "j_YlXP2bcicx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of batches in train_generator: {len(train_generator)}\")\n",
        "print(f\"Number of batches in val_generator: {len(val_generator)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:11.580601Z",
          "iopub.execute_input": "2025-05-02T14:08:11.580919Z",
          "iopub.status.idle": "2025-05-02T14:08:11.585863Z",
          "shell.execute_reply.started": "2025-05-02T14:08:11.580893Z",
          "shell.execute_reply": "2025-05-02T14:08:11.584736Z"
        },
        "trusted": true,
        "id": "jQXq4iAScicx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📌 Understanding ImageDataGenerator</font></h2>\n",
        "\n",
        "When we create `train_generator` using `flow_from_dataframe`, we're __not__ pre-generating all batches of images with their transformations. What we are doing is setting up a framework or a \"__pipeline__\" that knows how to fetch and transform the images when requested.\n",
        "\n",
        "The benefit of ImageDataGenerator is precisely this: it generates augmented images __on-the-fly__ during each step of each epoch. It doesn't pre-generate and store them.\n",
        "\n",
        "When we ask for `len(train_generator)`, it's just doing a calculation based on the total number of images and the batch size to tell us how many batches there will be. It doesn't mean those batches have been pre-generated."
      ],
      "metadata": {
        "id": "9trk62-Acicy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Dataset_Imbalances\"></a>\n",
        "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 4 | Addressing Dataset Imbalances</p>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "zvlWjOWzcicy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>🛠️ Addressing Imbalance Using Class Weights:</font></h2>\n",
        "\n",
        "To tackle our imbalanced image dataset, we'll utilize class weights. These weights assign more importance to underrepresented classes during training. The weights are computed inversely proportional to class frequencies using utilities like `compute_class_weight` from scikit-learn based on the distribution of images in each class. The formula is:\n",
        "\n",
        "$$ \\text{weight}(class) = \\frac{\\text{total samples}}{\\text{number of classes} \\times \\text{samples in that class}} $$\n",
        "\n",
        "These computed weights are then passed to the model\n"
      ],
      "metadata": {
        "id": "zYTCoEYYcicy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract class labels from the 'label' column of train_df\n",
        "class_labels = train_df['label'].unique()\n",
        "class_labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:18.553397Z",
          "iopub.execute_input": "2025-05-02T14:08:18.553765Z",
          "iopub.status.idle": "2025-05-02T14:08:18.559935Z",
          "shell.execute_reply.started": "2025-05-02T14:08:18.553738Z",
          "shell.execute_reply": "2025-05-02T14:08:18.559087Z"
        },
        "trusted": true,
        "id": "y9vvw7Iocicy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.class_indices"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:20.825492Z",
          "iopub.execute_input": "2025-05-02T14:08:20.826269Z",
          "iopub.status.idle": "2025-05-02T14:08:20.831301Z",
          "shell.execute_reply.started": "2025-05-02T14:08:20.826241Z",
          "shell.execute_reply": "2025-05-02T14:08:20.830509Z"
        },
        "trusted": true,
        "id": "L3IsFne8cicy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights\n",
        "weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=train_df['label'])\n",
        "weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:21.135318Z",
          "iopub.execute_input": "2025-05-02T14:08:21.136004Z",
          "iopub.status.idle": "2025-05-02T14:08:21.142779Z",
          "shell.execute_reply.started": "2025-05-02T14:08:21.135973Z",
          "shell.execute_reply": "2025-05-02T14:08:21.141933Z"
        },
        "trusted": true,
        "id": "JkdxY2hncic8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the computed weights to a dictionary for passing to model training\n",
        "class_weights = dict(zip(train_generator.class_indices.values(), weights))\n",
        "class_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:24.576985Z",
          "iopub.execute_input": "2025-05-02T14:08:24.577301Z",
          "iopub.status.idle": "2025-05-02T14:08:24.583052Z",
          "shell.execute_reply.started": "2025-05-02T14:08:24.577273Z",
          "shell.execute_reply": "2025-05-02T14:08:24.582217Z"
        },
        "trusted": true,
        "id": "44p6bXMscic9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📌 Understanding Class Label Mapping in ImageDataGenerator:</font></h2>\n",
        "\n",
        "When we create a generator using __`flow_from_dataframe`__ with the __`class_mode='categorical'`__ setting, the generator internally maps each unique class label in our `y_col` (in this case, the \"label\" column of __`train_df`__) to a unique integer. This mapping is done in alphabetical order, which means:\n",
        "\n",
        "- '__cardboard__' is mapped to __0__\n",
        "- '__glass__' is mapped to __1__\n",
        "- '__metal__' is mapped to __2__\n",
        "- '__paper__' is mapped to __3__\n",
        "- '__plastic__' is mapped to __4__\n",
        "- '__trash__' is mapped to __5__\n",
        "\n",
        "This mapping is stored in the __`train_generator.class_indices`__ dictionary. The keys of this dictionary are the class labels (e.g., 'cardboard', 'glass', etc.), and the corresponding values are the mapped integers (e.g., 0, 1, etc.).\n",
        "\n",
        "This mapping ensures that when we're using one-hot encoding, the correct position in the one-hot encoded vector corresponds to the appropriate class. For example, the one-hot encoded vector for 'cardboard' would be __`[1, 0, 0, 0, 0, 0]`__.\n",
        "\n",
        "When we computed the __`class_weights`__, we used this mapping to ensure the weights correspond correctly to the one-hot encoded labels during training."
      ],
      "metadata": {
        "id": "JZRJsqj8cic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Resnet50\"></a>\n",
        "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 5 | ResNet50 Built from Scratch</p>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "HlfQwKZwcic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Define_Scratch\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 5.1 |</span><span style='color:royalblue'> Defining the ResNet50 Architecture from Scratch</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "22UKDW-Bcic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "For this phase of our project, I've chosen to work with the __ResNet__ architecture, specifically its famous variant, __ResNet50__. The standout feature of ResNet architectures is the incorporation of \"__skip__\" or \"__shortcut__\" connections. These ingenious connections allow layers to skip intermediate layers and connect directly to subsequent ones. This design is pivotal in addressing the __vanishing gradient__ problem, enabling the efficient training of much deeper neural networks than previously possible.\n",
        "\n",
        "To build our ResNet50 model, we first lay the foundation by implementing its core component—the '__Residual Block__'. Here's a representation of this essential block:"
      ],
      "metadata": {
        "id": "0sWHOLsOcic_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/FarzadNekouee/Garbage_Classification_ResNet50_Scratch_to_Transfer-Learning/blob/master/images/Residual_Block.png?raw=true\" width=\"2400\">"
      ],
      "metadata": {
        "id": "lTvIcsOkcic_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(X, kernel_size, filters, reduce=False, stride=2):\n",
        "    \"\"\"\n",
        "    Implement a residual block for ResNet architectures.\n",
        "\n",
        "    Arguments:\n",
        "    X           -- input tensor of shape (m, height, width, channels)\n",
        "    kernel_size -- integer, kernel size of the middle convolutional layer in the main path\n",
        "    filters     -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    reduce      -- boolean, whether to reduce the spatial dimensions and increase depth;\n",
        "                    if True, applies 1x1 CONV layer to the shortcut path.\n",
        "    stride      -- integer, strides for the convolutional layer\n",
        "\n",
        "    Returns:\n",
        "    X           -- output of the identity block, tensor of shape (height, width, channels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. We will need this later to add back to the main path.\n",
        "    X_shortcut = X\n",
        "\n",
        "    if reduce:\n",
        "        # if we are to reduce the spatial size, apply a 1x1 CONV layer to the shortcut path\n",
        "        X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (stride,stride), padding = 'valid', kernel_initializer='he_normal')(X)\n",
        "        X = BatchNormalization(axis = 3)(X)\n",
        "        X = Activation('relu')(X)\n",
        "\n",
        "        X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (stride,stride), padding = 'valid', kernel_initializer='he_normal')(X_shortcut)\n",
        "        X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
        "    else:\n",
        "        # First component of main path\n",
        "        X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer='he_normal')(X)\n",
        "        X = BatchNormalization(axis = 3)(X)\n",
        "        X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (kernel_size, kernel_size), strides = (1,1), padding = 'same', kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a ReLU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:34.124388Z",
          "iopub.execute_input": "2025-05-02T14:08:34.125191Z",
          "iopub.status.idle": "2025-05-02T14:08:34.132845Z",
          "shell.execute_reply.started": "2025-05-02T14:08:34.125161Z",
          "shell.execute_reply": "2025-05-02T14:08:34.132054Z"
        },
        "trusted": true,
        "id": "9mxryXducic_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "<h2 align=\"left\"><font color=royalblue>📌 Understanding the Residual Block:</font></h2>\n",
        "    \n",
        "- To adjust the depth of the feature map, we employ a 1x1 CONV layer on the shortcut path (when `reduce=True`). This also allows us to modify the height and width of the feature map as well. However, to ensure consistent sizes when adding the feature maps from the main and shortcut paths at the end of the block, the first 1x1 convolution in the main path and the 1x1 convolution in the shortcut path must share the same stride.\n"
      ],
      "metadata": {
        "id": "xEzO2Vnecic_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "Now let's build our ResNet50 architecture as a function that takes `input_shape` and `classes` as arguments and outputs the model:"
      ],
      "metadata": {
        "id": "mYPuZK1jcidA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet_50(input_shape, classes):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    input_shape -- tuple shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer='he_normal')(X_input)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Block 2\n",
        "    X = residual_block(X, 3, [64, 64, 256], reduce=True, stride=1)\n",
        "    X = residual_block(X, 3, [64, 64, 256])\n",
        "    X = residual_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    # Block 3\n",
        "    X = residual_block(X, 3, [128, 128, 512], reduce=True, stride=2)\n",
        "    X = residual_block(X, 3, [128, 128, 512])\n",
        "    X = residual_block(X, 3, [128, 128, 512])\n",
        "    X = residual_block(X, 3, [128, 128, 512])\n",
        "\n",
        "    # Block 4\n",
        "    X = residual_block(X, 3, [256, 256, 1024], reduce=True, stride=2)\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    # Block 5\n",
        "    X = residual_block(X, 3, [512, 512, 2048], reduce=True, stride=2)\n",
        "    X = residual_block(X, 3, [512, 512, 2048])\n",
        "    X = residual_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    # Global Average Pooling to reduce spatial dimensions\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "\n",
        "    # Fully Connected Layer for classification\n",
        "    X = Dense(classes, activation='softmax')(X)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:41.672899Z",
          "iopub.execute_input": "2025-05-02T14:08:41.673559Z",
          "iopub.status.idle": "2025-05-02T14:08:41.682271Z",
          "shell.execute_reply.started": "2025-05-02T14:08:41.673526Z",
          "shell.execute_reply": "2025-05-02T14:08:41.681349Z"
        },
        "trusted": true,
        "id": "QRs5gkoNcidA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "With the intricate design of ResNet50 and our small dataset, the model tends to overfit on the training data. To address this, I've tailored the ResNet architecture by introducing a Dropout layer after the `GlobalAveragePooling2D` layer:"
      ],
      "metadata": {
        "id": "WlYcQgv5cidB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Modified_ResNet50(input_shape, classes):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    input_shape -- tuple shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer='he_normal')(X_input)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = residual_block(X, 3, [64, 64, 256], reduce=True, stride=1)\n",
        "    X = residual_block(X, 3, [64, 64, 256])\n",
        "    X = residual_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    # Stage 3\n",
        "    X = residual_block(X, 3, [128, 128, 512], reduce=True, stride=2)\n",
        "    X = residual_block(X, 3, [128, 128, 512])\n",
        "    X = residual_block(X, 3, [128, 128, 512])\n",
        "    X = residual_block(X, 3, [128, 128, 512])\n",
        "\n",
        "    # Stage 4\n",
        "    X = residual_block(X, 3, [256, 256, 1024], reduce=True, stride=2)\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "    X = residual_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    # Stage 5\n",
        "    X = residual_block(X, 3, [512, 512, 2048], reduce=True, stride=2)\n",
        "    X = residual_block(X, 3, [512, 512, 2048])\n",
        "    X = residual_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    # Global Average Pooling to reduce spatial dimensions\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "\n",
        "    # Add Dropout to prevent overfitting\n",
        "    X = Dropout(0.5)(X)\n",
        "\n",
        "    # Fully Connected Layer for classification\n",
        "    X = Dense(classes, activation='softmax')(X)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs = X_input, outputs = X, name='Modified_ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:46.262856Z",
          "iopub.execute_input": "2025-05-02T14:08:46.263609Z",
          "iopub.status.idle": "2025-05-02T14:08:46.272029Z",
          "shell.execute_reply.started": "2025-05-02T14:08:46.263563Z",
          "shell.execute_reply": "2025-05-02T14:08:46.271179Z"
        },
        "trusted": true,
        "id": "ugDNS8u8cidB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Afterward, I am going to initialize our modified ResNet50 model:"
      ],
      "metadata": {
        "id": "KnbYI9LucidC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the shape of the input images and number of classes\n",
        "input_shape = (384, 384, 3)\n",
        "num_classes = 6\n",
        "\n",
        "# Initialize the modified ResNet50 model with the specified parameters\n",
        "modified_resnet50_model = Modified_ResNet50(input_shape=input_shape, classes=num_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:50.346374Z",
          "iopub.execute_input": "2025-05-02T14:08:50.347022Z",
          "iopub.status.idle": "2025-05-02T14:08:51.340581Z",
          "shell.execute_reply.started": "2025-05-02T14:08:50.346992Z",
          "shell.execute_reply": "2025-05-02T14:08:51.339654Z"
        },
        "trusted": true,
        "id": "6_GS4HcacidC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "Now, let's visualize the architecture of our model:"
      ],
      "metadata": {
        "id": "BCe8ebu_cidC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(modified_resnet50_model, show_shapes=True, show_layer_names=False, dpi=120)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:08:56.83683Z",
          "iopub.execute_input": "2025-05-02T14:08:56.83764Z",
          "iopub.status.idle": "2025-05-02T14:08:58.593521Z",
          "shell.execute_reply.started": "2025-05-02T14:08:56.837608Z",
          "shell.execute_reply": "2025-05-02T14:08:58.592091Z"
        },
        "trusted": true,
        "id": "mOuU7miHcidC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Finally, lets examine our model summary to understand the number of parameters involved:"
      ],
      "metadata": {
        "id": "2P9bR7UocidD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modified_resnet50_model.summary()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T14:09:11.842155Z",
          "iopub.execute_input": "2025-05-02T14:09:11.842495Z",
          "iopub.status.idle": "2025-05-02T14:09:12.207902Z",
          "shell.execute_reply.started": "2025-05-02T14:09:11.842465Z",
          "shell.execute_reply": "2025-05-02T14:09:12.206983Z"
        },
        "trusted": true,
        "id": "pSlKCCELcidD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "Our model comprises approximately 23.5 million trainable parameters."
      ],
      "metadata": {
        "id": "TyzY78wdcidD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Train_Scratch\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 5.2 |</span><span style='color:royalblue'> Training the Defined ResNet50 Model</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "CSvLw1SScidD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>📝 Preparing the Model for Training:</font></h2>\n",
        "    \n",
        "Now, I am going to get our model prepared for training:\n",
        "    \n",
        "- I will choose the `adam` optimizer, known for adapting learning rates throughout training.\n",
        "- I will use the `categorical_crossentropy` loss function, suitable for multi-class classification tasks.\n",
        "- I will select `accuracy` as a metric for simplicity. Given our dataset's imbalance, I will utilize additional metrics to better assess our model performance later."
      ],
      "metadata": {
        "id": "j6wpmZs5cidE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modified_resnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:09:26.494832Z",
          "iopub.execute_input": "2025-05-02T14:09:26.495821Z",
          "iopub.status.idle": "2025-05-02T14:09:26.508361Z",
          "shell.execute_reply.started": "2025-05-02T14:09:26.495789Z",
          "shell.execute_reply": "2025-05-02T14:09:26.507635Z"
        },
        "trusted": true,
        "id": "LOV7hiyrcidE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>🛠️ Enhancing Training with Callbacks:</font></h2>\n",
        "    \n",
        "Next, I will define two key callbacks to enhance and monitor our training process:\n",
        "\n",
        "1️⃣ **ReduceLROnPlateau**:\n",
        "   - The `ReduceLROnPlateau` callback is used to reduce the learning rate by half (factor=0.5) whenever the validation loss does not improve for 15 consecutive epochs. This helps to adjust the learning rate dynamically, allowing the model to get closer to the global minimum of the loss function when progress has plateaued. This strategy can improve the convergence of the training process.\n",
        "\n",
        "    \n",
        "2️⃣ **EarlyStopping**:\n",
        "   - The `EarlyStopping` callback is employed to monitor the validation loss and halt the training process when there hasn't been any improvement for 30 epochs, ensuring that the model doesn't waste computational resources and time. Furthermore, this callback restores the best weights from the training process, ensuring we conclude with the optimal model configuration from the epochs."
      ],
      "metadata": {
        "id": "SD_Sbb_scidE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>🎯 Note:</font></h2>\n",
        "    \n",
        "I am not using the `ModelCheckpoint` callback in this context because I could save the model using `model.save()` after training. This saves the best weights from our training due to the `restore_best_weights=True` option in the `EarlyStopping` callback. The `ModelCheckpoint` callback is beneficial, especially in environments where training could be interrupted; it ensures you have a saved version of the best model up to the point of interruption. But if you're sure about the stability of your training environment, you might not find a necessity for this callback."
      ],
      "metadata": {
        "id": "Uxk67swVcidE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=0.00001)\n",
        "\n",
        "# Add EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=50, restore_best_weights=True, verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:09:44.18302Z",
          "iopub.execute_input": "2025-05-02T14:09:44.183839Z",
          "iopub.status.idle": "2025-05-02T14:09:44.18818Z",
          "shell.execute_reply.started": "2025-05-02T14:09:44.183807Z",
          "shell.execute_reply": "2025-05-02T14:09:44.187325Z"
        },
        "trusted": true,
        "id": "Ogmp7JDtcidF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>🚀 Model Training:</font></h2>\n",
        "\n",
        "In this step, I am going to set our model up for training using the `fit` method:\n",
        "\n",
        "- **train_generator**: This feeds our model with batches of training data.\n",
        "- **steps_per_epoch**: Indicates the number of batches in each epoch. Given that our generator produces batches of images continuously, `steps_per_epoch` ensures the fit process understands when to consider an epoch completed.\n",
        "- **epochs**: The total number of iterations over the entire dataset. I will set this to `200` for our model.\n",
        "- **validation_data**: Like the training generator, this provides batches of validation data for model evaluation after each epoch.\n",
        "- **validation_steps**: Specifies the number of batches from the validation data to evaluate the model on after each epoch.\n",
        "- **class_weight**: Given the imbalanced nature of our dataset, we're utilizing the weights we calculated earlier to assign different importance levels to each class. This helps to ensure our model remains unbiased towards the majority class.\n",
        "- **callbacks**: The list of callbacks we've previously defined. They include the `reduce_lr` and `early_stopping` functions, which help in dynamically adjusting the learning rate and halting training when the model ceases to improve."
      ],
      "metadata": {
        "id": "BjYtmXKlcidF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of batches in train_generator: {len(train_generator)}\")\n",
        "print(f\"Number of batches in val_generator: {len(val_generator)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:09:49.796338Z",
          "iopub.execute_input": "2025-05-02T14:09:49.797015Z",
          "iopub.status.idle": "2025-05-02T14:09:49.801161Z",
          "shell.execute_reply.started": "2025-05-02T14:09:49.796985Z",
          "shell.execute_reply": "2025-05-02T14:09:49.800271Z"
        },
        "trusted": true,
        "id": "wDCgYyGfcidG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Assigned Class Weights:\")\n",
        "class_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:09:50.231884Z",
          "iopub.execute_input": "2025-05-02T14:09:50.232203Z",
          "iopub.status.idle": "2025-05-02T14:09:50.238277Z",
          "shell.execute_reply.started": "2025-05-02T14:09:50.232177Z",
          "shell.execute_reply": "2025-05-02T14:09:50.237365Z"
        },
        "trusted": true,
        "id": "EZygTwJocidG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Train the model\n",
        "history = modified_resnet50_model.fit(train_generator,\n",
        "                                      steps_per_epoch=len(train_generator),\n",
        "                                      epochs=num_epochs,\n",
        "                                      validation_data=val_generator,\n",
        "                                      validation_steps=len(val_generator),\n",
        "                                      class_weight=class_weights,\n",
        "                                      callbacks=[reduce_lr, early_stopping])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T14:09:56.393118Z",
          "iopub.execute_input": "2025-05-02T14:09:56.393814Z",
          "iopub.status.idle": "2025-05-02T16:23:23.166286Z",
          "shell.execute_reply.started": "2025-05-02T14:09:56.393767Z",
          "shell.execute_reply": "2025-05-02T16:23:23.165365Z"
        },
        "trusted": true,
        "id": "C0hbgQRycidG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Eval_Scratch\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 5.3 |</span><span style='color:royalblue'> Evaluating the Defined ResNet50 Model</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)\n"
      ],
      "metadata": {
        "id": "hU3aHQUfcidG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "During the evaluation process, I will encompass two distinct phases:\n",
        "    \n",
        "- Visualizing the Learning Curves\n",
        "- Performance Metrics Assessment"
      ],
      "metadata": {
        "id": "EqW3vO5jcidH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"curves_scratch\"></a>\n",
        "## <b><span style='color:darkturquoise'>Step 5.3.1 |</span><span style='color:royalblue'> Visualizing the Learning Curves</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "TDnsLuVLcidH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "In this step, I will define a function to visualize the learning curves for Loss and Accuracy across epochs for both training and validation sets, providing insights into the quality of our trained model:"
      ],
      "metadata": {
        "id": "ZrlRvxSwcidK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(history, start_epoch=5):\n",
        "    \"\"\"\n",
        "    Plot training and validation loss and accuracy curves.\n",
        "\n",
        "    Parameters:\n",
        "    - history: Training history (output from the model's fit method).\n",
        "    - start_epoch: Epoch from which to start plotting. Default is 5 (i.e., plot from epoch 6 onwards).\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the history.history dict to a pandas DataFrame\n",
        "    df = pd.DataFrame(history.history)\n",
        "\n",
        "    # Plot the curves from the specified epoch onwards\n",
        "    df = df.iloc[start_epoch-1:]\n",
        "\n",
        "    # Set the style of seaborn for better visualization\n",
        "    sns.set(rc={'axes.facecolor': '#f0f0fc'}, style='darkgrid')\n",
        "\n",
        "    # Plotting the learning curves\n",
        "    plt.figure(figsize=(15,6))\n",
        "\n",
        "    # Plotting the training and validation loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.lineplot(x=df.index, y=df['loss'], color='royalblue', label='Train Loss')\n",
        "    sns.lineplot(x=df.index, y=df['val_loss'], color='orangered', linestyle='--', label='Validation Loss')\n",
        "    plt.title('Loss Evolution')\n",
        "\n",
        "    # Plotting the training and validation accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.lineplot(x=df.index, y=df['accuracy'], color='royalblue', label='Train Accuracy')\n",
        "    sns.lineplot(x=df.index, y=df['val_accuracy'], color='orangered', linestyle='--', label='Validation Accuracy')\n",
        "    plt.title('Accuracy Evolution')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:23:51.676632Z",
          "iopub.execute_input": "2025-05-02T16:23:51.677363Z",
          "iopub.status.idle": "2025-05-02T16:23:51.684259Z",
          "shell.execute_reply.started": "2025-05-02T16:23:51.67733Z",
          "shell.execute_reply": "2025-05-02T16:23:51.683352Z"
        },
        "trusted": true,
        "id": "k6VeWKoXcidL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curves(history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:23:57.824112Z",
          "iopub.execute_input": "2025-05-02T16:23:57.824456Z",
          "iopub.status.idle": "2025-05-02T16:23:58.321321Z",
          "shell.execute_reply.started": "2025-05-02T16:23:57.824405Z",
          "shell.execute_reply": "2025-05-02T16:23:58.320507Z"
        },
        "trusted": true,
        "id": "dIH3a_lgcidL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>💡 Observations:</font></h2>\n",
        "\n",
        "- **Training Metrics**: The model learns the training data well, as seen by decreasing loss and increasing accuracy.\n",
        "- **Validation Fluctuations**: The validation loss has many ups and downs, suggesting the model isn't consistent on unseen data.\n",
        "- **Overfitting Signs**: There's a clear difference between training and validation performance, hinting at overfitting.\n",
        "\n",
        "<h3 align=\"left\"><font color=royalblue> 🎯 Reasons for Fluctuations:</font></h3>    \n",
        "\n",
        "1. **Aggressive Augmentation**: Our data changes might be too strong, making the model see very different images during training.\n",
        "2. **Small Dataset**: Using a deep model like ResNet50 on just 2000 images can make it memorize data rather than learn patterns, leading to unstable results.\n",
        "3. **Class Weights**: While they help with imbalanced data, they might cause the model to be too focused on certain classes, affecting validation.\n",
        "4. **Batch Size & Learning Rate**: Small batches can cause noisy updates, and a high learning rate might make the model skip optimal points.\n"
      ],
      "metadata": {
        "id": "NtIR_Hx7cidL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"metrics_scratch\"></a>\n",
        "## <b><span style='color:darkturquoise'>Step 5.3.2 |</span><span style='color:royalblue'> Performance Metrics Assessment</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "duRK0mAucidM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "In this step, I will craft a function to evaluate our model using both performance metrics and a confusion matrix:"
      ],
      "metadata": {
        "id": "nzrITNRccidM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_performance(model, val_generator, class_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the model's performance on the validation set and print the classification report.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model.\n",
        "    - val_generator: Validation data generator.\n",
        "    - class_labels: List of class names.\n",
        "\n",
        "    Returns:\n",
        "    - report: Classification report as a string.\n",
        "    \"\"\"\n",
        "\n",
        "    # Getting all the true labels for the validation set\n",
        "    true_labels = val_generator.classes\n",
        "\n",
        "    # Get the class labels (names) from the generator\n",
        "    class_labels = list(val_generator.class_indices.keys())\n",
        "\n",
        "    # To get the predicted labels, we predict using the model\n",
        "    predictions = model.predict(val_generator, steps=len(val_generator))\n",
        "\n",
        "    # Take the argmax to get the predicted class indices.\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Extracting true labels from the validation generator\n",
        "    true_labels = val_generator.classes\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(true_labels, predicted_labels, target_names=class_labels)\n",
        "    print(report)\n",
        "    print('\\n')\n",
        "\n",
        "    # Define a custom colormap\n",
        "    colors = [\"white\", \"royalblue\"]\n",
        "    cmap_cm = LinearSegmentedColormap.from_list(\"cmap_cm\", colors)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    # Plotting confusion matrix using seaborn\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, cmap=cmap_cm, fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:24:31.327526Z",
          "iopub.execute_input": "2025-05-02T16:24:31.327876Z",
          "iopub.status.idle": "2025-05-02T16:24:31.334782Z",
          "shell.execute_reply.started": "2025-05-02T16:24:31.327845Z",
          "shell.execute_reply": "2025-05-02T16:24:31.333868Z"
        },
        "trusted": true,
        "id": "HE7O8oUAcidM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model_performance(modified_resnet50_model, val_generator, class_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:24:38.422978Z",
          "iopub.execute_input": "2025-05-02T16:24:38.423307Z",
          "iopub.status.idle": "2025-05-02T16:24:43.193691Z",
          "shell.execute_reply.started": "2025-05-02T16:24:38.423279Z",
          "shell.execute_reply": "2025-05-02T16:24:43.192796Z"
        },
        "trusted": true,
        "id": "L8VyZeXgcidM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>💡 Model Performance Inferences:</font></h2>\n",
        "\n",
        "- 1️⃣ **Overall Performance**:\n",
        "   - The model showcases good accuracy and balanced metrics for most categories.\n",
        "\n",
        "    \n",
        "- 2️⃣ **High Performers**:\n",
        "   - `cardboard`: Stands out with exceptional performance.\n",
        "   - `paper`: Delivers strong results.\n",
        "   - `glass`: Holds its own, even with a notable representation in the dataset.\n",
        "\n",
        "    \n",
        "- 3️⃣ **Areas to Improve**:\n",
        "   - `trash`: The model finds this category a bit challenging, likely due to its lesser representation in the dataset.\n",
        "\n",
        "    \n",
        "- 4️⃣ **Class Weights Impact**:\n",
        "   - Even with class weights, certain categories like `trash` pose challenges.\n",
        "   - Categories with higher representation, such as `paper`, still perform admirably.\n",
        "\n",
        "\n",
        "    \n",
        "<h3 align=\"left\"><font color=royalblue> 🎯 Recommendation:</font></h3>\n",
        "    \n",
        "Considering the challenges in classifying certain categories, implementing **transfer learning** could provide an improvement. Using pre-trained models and fine-tuning them for this specific task might help in better distinguishing between classes like `glass`, `plastic`, and `metal` and also improve performance on the `trash` category.\n"
      ],
      "metadata": {
        "id": "L7_aSTCtcidN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Transfer_Learning\"></a>\n",
        "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 6 | ResNet50 with Transfer Learning</p>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "2F64Sk5ucidN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>🔄 Why We Chose Transfer Learning for Garbage Classification</font></h2>\n",
        "\n",
        "__Classifying garbage__ is notably tough because of __the vast variety of items in each category__. With basic models, we might not achieve the best results. When using intricate models like __ResNet50__ on a smaller dataset, overfitting becomes a concern, and we might not see optimal performance. Adding __aggressive data augmentation__ provides some relief, but it's still not enough to train complex models like ResNet50 effectively, especially when starting from scratch. The uneven distribution of data types compounds the issue, as we aim for consistent model performance across all garbage types.\n",
        "\n",
        "This is where __Transfer Learning__ shines. Models pretrained on extensive datasets have learned features that can identify subtle differences between challenging categories. With transfer learning, we don't just accept the pretrained model as it is. Instead, we modify and fine-tune certain parts, especially the deeper layers, to cater to our specific needs. This approach lets us harness the power of established features while adapting the model to our dataset's specifics. As a result, our model becomes more robust and is less prone to overfitting."
      ],
      "metadata": {
        "id": "IUGqDVVFcidN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Define_tf\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 6.1 |</span><span style='color:royalblue'> Loading ResNet50 with Pre-trained Weights</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "xNoEAAd7cidN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "First of all, I am going to load the ResNet50 architecture pre-trained on the __ImageNet dataset__. I will exclude the top classifier layer to adjust for our specific 6-class task and set the input shape to `(384, 384, 3)` to align with our dataset's image dimensions:"
      ],
      "metadata": {
        "id": "Kv4GpbuMcidN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model with weights pre-trained on ImageNet\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(384, 384, 3))"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T16:25:08.980252Z",
          "iopub.execute_input": "2025-05-02T16:25:08.981119Z",
          "iopub.status.idle": "2025-05-02T16:25:11.347284Z",
          "shell.execute_reply.started": "2025-05-02T16:25:08.981087Z",
          "shell.execute_reply": "2025-05-02T16:25:11.346609Z"
        },
        "trusted": true,
        "id": "BzgCjA4AcidO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Let's take a look at our `base_model` summary:"
      ],
      "metadata": {
        "id": "cqb5yJeacidO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T16:25:19.454144Z",
          "iopub.execute_input": "2025-05-02T16:25:19.454511Z",
          "iopub.status.idle": "2025-05-02T16:25:19.819318Z",
          "shell.execute_reply.started": "2025-05-02T16:25:19.454464Z",
          "shell.execute_reply": "2025-05-02T16:25:19.802478Z"
        },
        "trusted": true,
        "id": "oP6hs8CQcidO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Our `base_model` contains approximately 23.5 million trainable parameters!"
      ],
      "metadata": {
        "id": "ex5k6VkMcidP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "The name __ResNet50__ refers to a residual network with 50 weight layers. However, when you include other types of layers like Batch Normalization, Activation layers, etc., the total count goes up. Let's find it:"
      ],
      "metadata": {
        "id": "Fup9fHi9cidP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(base_model.layers)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:25:59.166208Z",
          "iopub.execute_input": "2025-05-02T16:25:59.166568Z",
          "iopub.status.idle": "2025-05-02T16:25:59.172317Z",
          "shell.execute_reply.started": "2025-05-02T16:25:59.166536Z",
          "shell.execute_reply": "2025-05-02T16:25:59.171485Z"
        },
        "trusted": true,
        "id": "IBIQSY_LcidP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>🔍 Deciding the Level of Transfer Learning</font></h2>\n",
        "\n",
        "The level of transfer learning we adopt depends on two key aspects:\n",
        "    \n",
        "- 1️⃣ The size of our dataset (small or large).  \n",
        "- 2️⃣ How similar our dataset is to the original dataset the pretrained model was trained on.\n",
        "\n",
        "Given our circumstances, our dataset is small and varies from the original dataset (`imagenet`). If we kept the higher-level features of the pretrained model unchanged, they might not be as effective, since they've been tailored to a different set of data. Fully fine-tuning the entire model on our limited dataset isn't ideal either, as it could lead to overfitting.\n",
        "\n",
        "A balanced approach is to freeze the earlier layers, which capture broad and general features, and fine-tune the latter layers."
      ],
      "metadata": {
        "id": "IguAtmyxcidP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "In our earlier exploration, when implementing ResNet50 from scratch, we delved into the architecture which comprises:\n",
        "\n",
        "- Block 1: An initial convolution and max pooling.\n",
        "- Block 2: 3 units (residual blocks)\n",
        "- Block 3: 4 units\n",
        "- Block 4: 6 units\n",
        "- Block 5: 3 units\n",
        "\n",
        "Given this structure and our objective to balance the amount of layers we freeze, we determined that __the end of Block 4__ would be optimal. This ensures that the broad and general features from the initial blocks are retained, while the more specific features in the latter blocks can be fine-tuned to our dataset. Let's print out the names of the layers around the end of Block 4 to find the precise layer name we want to freeze up to:"
      ],
      "metadata": {
        "id": "fYC9vP4jcidQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "    if 140 <= i <= 150:\n",
        "        print(i, layer.name)"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T16:26:32.167139Z",
          "iopub.execute_input": "2025-05-02T16:26:32.167507Z",
          "iopub.status.idle": "2025-05-02T16:26:32.17283Z",
          "shell.execute_reply.started": "2025-05-02T16:26:32.167471Z",
          "shell.execute_reply": "2025-05-02T16:26:32.171955Z"
        },
        "trusted": true,
        "id": "3UQP-_ubcidQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "From the list provided, the end of Block 4 (conv4) is represented by __`conv4_block6_out`__, which is layer number __`142`__. Now, let's freeze the layers up to __`conv4_block6_out`__:"
      ],
      "metadata": {
        "id": "DHH2u7AocidQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers up to conv4_block6_out\n",
        "for layer in base_model.layers[:143]: # include the layer 142\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:26:36.431211Z",
          "iopub.execute_input": "2025-05-02T16:26:36.431875Z",
          "iopub.status.idle": "2025-05-02T16:26:36.43907Z",
          "shell.execute_reply.started": "2025-05-02T16:26:36.43184Z",
          "shell.execute_reply": "2025-05-02T16:26:36.43811Z"
        },
        "trusted": true,
        "id": "DWPRlwZKcidQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Afterward, I am going to extend the pre-trained base_model (ResNet50) by adding custom layers to tailor it for our specific classification task. After extracting features using ResNet50, we use a __Global Average Pooling__ layer to condense the spatial dimensions. A __dropout__ layer is added for regularization, reducing the risk of overfitting. Finally, a __dense__ layer with a softmax activation function is employed to classify the inputs into our 6 distinct classes:"
      ],
      "metadata": {
        "id": "c05_XxaFcidR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(6, activation='softmax')(x)\n",
        "\n",
        "transfer_resnet50_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "transfer_resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:26:41.056158Z",
          "iopub.execute_input": "2025-05-02T16:26:41.056512Z",
          "iopub.status.idle": "2025-05-02T16:26:41.094348Z",
          "shell.execute_reply.started": "2025-05-02T16:26:41.056481Z",
          "shell.execute_reply": "2025-05-02T16:26:41.093194Z"
        },
        "trusted": true,
        "id": "sWf6LbQFcidR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "Next, let's visualize the architecture of our new model:"
      ],
      "metadata": {
        "id": "AuHI2mDWcidR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(transfer_resnet50_model, show_shapes=True, show_layer_names=False, dpi=120)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:27:23.626136Z",
          "iopub.execute_input": "2025-05-02T16:27:23.626493Z",
          "iopub.status.idle": "2025-05-02T16:27:25.369485Z",
          "shell.execute_reply.started": "2025-05-02T16:27:23.626452Z",
          "shell.execute_reply": "2025-05-02T16:27:25.368491Z"
        },
        "trusted": true,
        "id": "DjBRNNzJcidR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "We can also examine our model summary to understand the number of parameters involved:"
      ],
      "metadata": {
        "id": "3VyA911ocidR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_resnet50_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:28:12.931951Z",
          "iopub.execute_input": "2025-05-02T16:28:12.932649Z",
          "iopub.status.idle": "2025-05-02T16:28:13.293125Z",
          "shell.execute_reply.started": "2025-05-02T16:28:12.932617Z",
          "shell.execute_reply": "2025-05-02T16:28:13.291464Z"
        },
        "trusted": true,
        "id": "hkygrqNAcidS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h3 align=\"left\"><font color=royalblue>📉 Reduction in Trainable Parameters After Freezing Blocks</font></h3>\n",
        "\n",
        "As observed from the model summary, after freezing the first four blocks of our ResNet architecture, the number of trainable parameters significantly reduced to approximately 15 million, down from the initial 23.5 million. This change ensures a more balanced approach, reducing the risk of overfitting while capitalizing on the pre-trained knowledge of the model."
      ],
      "metadata": {
        "id": "JZtZwC0FcidS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Preprocess_tf\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 6.2 |</span><span style='color:royalblue'> Applying ResNet50-specific Image Preprocessing </span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "y0fis5uvcidS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h3 align=\"left\"><font color=royalblue>💡 Updating Data Preprocessing for ResNet50 </font></h3>\n",
        "\n",
        "ResNet50 was originally trained with a unique preprocessing on the __ImageNet__ dataset. Not adhering to this preprocessing can result in reduced model performance. Therefore, we'll need to modify the generators we set up in __Step 3.3__. The two key changes are:\n",
        "    \n",
        "- Using the `preprocess_input` of ResNet50 as the `preprocessing_function` for `ImageDataGenerator`.\n",
        "- Removing the `rescale` argument from `ImageDataGenerator`, as this is already handled by `preprocess_input`.\n",
        "\n",
        "Here's the updated approach:"
      ],
      "metadata": {
        "id": "kU2XClpUcidS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slight Augmentation settings for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=60,                  # Randomly rotate the images by up to 60 degrees\n",
        "    width_shift_range=0.15,             # Randomly shift images horizontally by up to 15% of the width\n",
        "    height_shift_range=0.15,            # Randomly shift images vertically by up to 15% of the height\n",
        "    zoom_range=0.20,                    # Randomly zoom in or out by up to 20%\n",
        "    horizontal_flip=True,               # Randomly flip images horizontally\n",
        "    vertical_flip=True,                 # Randomly flip images vertically\n",
        "    shear_range=0.05,                   # Apply slight shear transformations\n",
        "    brightness_range=[0.9, 1.1],        # Vary brightness between 90% to 110% of original\n",
        "    channel_shift_range=10,             # Randomly shift channels (can change colors of images slightly but less aggressively)\n",
        "    fill_mode='nearest',                 # Fill in missing pixels using the nearest filled value\n",
        "    preprocessing_function=preprocess_input  # Add this line\n",
        ")\n",
        "\n",
        "# For the validation set, you might not have augmentation:\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  # Add this line"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:28:46.105994Z",
          "iopub.execute_input": "2025-05-02T16:28:46.10681Z",
          "iopub.status.idle": "2025-05-02T16:28:46.111918Z",
          "shell.execute_reply.started": "2025-05-02T16:28:46.106776Z",
          "shell.execute_reply": "2025-05-02T16:28:46.111024Z"
        },
        "trusted": true,
        "id": "JIV3GdJ_cidS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "    \n",
        "Let's utilize the above generators to produce data batches for both the training and validation phases:"
      ],
      "metadata": {
        "id": "p-q-RAT7cidT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using flow_from_dataframe to generate batches\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,                  # DataFrame containing training data\n",
        "    x_col=\"filepath\",                    # Column with paths to image files\n",
        "    y_col=\"label\",                       # Column with image labels\n",
        "    target_size=(384, 384),              # Resize all images to size of 384x384\n",
        "    batch_size=32,                       # Number of images per batch\n",
        "    class_mode='categorical',            # One-hot encode labels\n",
        "    seed=42,                             # Seed for random number generator to ensure reproducibility\n",
        "    shuffle=False                        # Data is not shuffled; order retained from DataFrame\n",
        ")\n",
        "\n",
        "\n",
        "# Generate validation batches from the validation dataframe\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,                    # DataFrame containing validation data\n",
        "    x_col=\"filepath\",                    # Column with paths to image files\n",
        "    y_col=\"label\",                       # Column with image labels\n",
        "    target_size=(384, 384),              # Resize all images to size of 384x384\n",
        "    batch_size=32,                       # Number of images per batch\n",
        "    class_mode='categorical',            # One-hot encode labels\n",
        "    seed=42,                             # Seed for random number generator to ensure reproducibility\n",
        "    shuffle=False                        # Data is not shuffled; order retained from DataFrame\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:29:01.959036Z",
          "iopub.execute_input": "2025-05-02T16:29:01.959578Z",
          "iopub.status.idle": "2025-05-02T16:29:03.763833Z",
          "shell.execute_reply.started": "2025-05-02T16:29:01.959543Z",
          "shell.execute_reply": "2025-05-02T16:29:03.762854Z"
        },
        "trusted": true,
        "id": "Li5QjLmHcidT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Train_tf\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 6.3 |</span><span style='color:royalblue'> Fine-tuning the Transfer Learning ResNet50 Model</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "hiLsyHpDcidT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "In this step, I am going to fine-tuning our model on our garbage dataset. Again, I will employ callbacks to adjust the learning rate when needed and to halt training early if there's no improvement, ensuring efficient and optimal training. The model will be also trained using class weights to account for potential class imbalances in the data."
      ],
      "metadata": {
        "id": "3XzPauu_cidT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Total number of epochs\n",
        "num_epochs = 50\n",
        "\n",
        "# Train the model\n",
        "history = transfer_resnet50_model.fit(train_generator,\n",
        "                                      steps_per_epoch=len(train_generator),\n",
        "                                      epochs=num_epochs,\n",
        "                                      validation_data=val_generator,\n",
        "                                      validation_steps=len(val_generator),\n",
        "                                      class_weight=class_weights,\n",
        "                                      callbacks=[reduce_lr, early_stopping])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T16:29:08.385561Z",
          "iopub.execute_input": "2025-05-02T16:29:08.38588Z",
          "iopub.status.idle": "2025-05-02T17:04:50.042147Z",
          "shell.execute_reply.started": "2025-05-02T16:29:08.385855Z",
          "shell.execute_reply": "2025-05-02T17:04:50.041251Z"
        },
        "trusted": true,
        "id": "JC-TpHxgcidT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Eval_tf\"></a>\n",
        "# <b><span style='color:darkturquoise'>Step 6.4 |</span><span style='color:royalblue'> Evaluating the Transfer Learning ResNet50 Model</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)\n"
      ],
      "metadata": {
        "id": "kiAOZ3CUcidT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "\n",
        "We once again, I am going to conduct our evaluation in two steps."
      ],
      "metadata": {
        "id": "-TxLtbITcidU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"curves_tf\"></a>\n",
        "## <b><span style='color:darkturquoise'>Step 6.4.1 |</span><span style='color:royalblue'> Visualizing the Learning Curves</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "8fhj9zn4cidU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curves(history, start_epoch=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T17:05:15.081513Z",
          "iopub.execute_input": "2025-05-02T17:05:15.081861Z",
          "iopub.status.idle": "2025-05-02T17:05:15.57137Z",
          "shell.execute_reply.started": "2025-05-02T17:05:15.081829Z",
          "shell.execute_reply": "2025-05-02T17:05:15.570381Z"
        },
        "trusted": true,
        "id": "BwzTbV5ecidU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>💡 Fine-Tuned ResNet50 Observations:</font></h2>\n",
        "\n",
        "- 1️⃣ **Loss Evolution**:\n",
        "   - **Train Loss**: Rapidly decreases and stabilizes after around 10 epochs.\n",
        "   - **Validation Loss**: Starts off high but quickly converges to a lower value.\n",
        "\n",
        "    \n",
        "- 2️⃣ **Accuracy Evolution**:\n",
        "   - **Train Accuracy**: Rapid ascent, approaching 100%. This demonstrates the model's capability to adapt quickly to the training data.\n",
        "   - **Validation Accuracy**: Impressive progress, reaching around 96% in just a few epochs and maintaining that level. This is a significant improvement over the scratch-built model.\n",
        "\n",
        "    \n",
        "- 3️⃣ **Comparison with Scratch-Built ResNet50**:\n",
        "   - The fine-tuned ResNet50 achieves high validation accuracy much faster, showcasing the benefits of transfer learning.\n",
        "   - The disparity between training and validation metrics is less pronounced than before, which is a positive sign.\n",
        "\n",
        "<h3 align=\"left\"><font color=royalblue> 🎯 Inference:</font></h3>\n",
        "\n",
        "The fine-tuned ResNet50 benefits from previous learnings, allowing for rapid convergence and a commendable validation accuracy of 96% within a few epochs. The performance is superior to the scratch-built variant, highlighting the advantages of transfer learning."
      ],
      "metadata": {
        "id": "EgvajEBqcidU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"metrics_tf\"></a>\n",
        "## <b><span style='color:darkturquoise'>Step 6.4.2 |</span><span style='color:royalblue'> Performance Metrics Assessment</span></b>\n",
        "⬆️ [Tabel of Contents](#contents_tabel)"
      ],
      "metadata": {
        "id": "yTHAlF_OcidU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model_performance(transfer_resnet50_model, val_generator, class_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-02T17:05:25.041194Z",
          "iopub.execute_input": "2025-05-02T17:05:25.041533Z",
          "iopub.status.idle": "2025-05-02T17:05:30.55512Z",
          "shell.execute_reply.started": "2025-05-02T17:05:25.041503Z",
          "shell.execute_reply": "2025-05-02T17:05:30.554292Z"
        },
        "trusted": true,
        "id": "ZQn7P8LbcidU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:125%; text-align:left\">\n",
        "<h2 align=\"left\"><font color=royalblue>💡 Model Performance Inferences:</font></h2>\n",
        "\n",
        "- 1️⃣ **Overall Accuracy**: The model boasts an impressive accuracy.\n",
        "- 2️⃣ **Cardboard**,  **Glass**, **Metal**, **Paper**, and **Plastic** are standout performers, demonstrating near-perfect results.\n",
        "- 3️⃣ **Trash** also put up strong performances, with both precision and recall being commendable.\n",
        "- 4️⃣ Consistent F1-scores across categories highlight the model's reliability in making balanced predictions.\n",
        "\n",
        "    \n",
        "<h3 align=\"left\"><font color=royalblue> 🎯 Inference:</font></h3>\n",
        "    \n",
        "With transfer learning, the ResNet50 model has shown noticeable improvements compared to its from-scratch counterpart. This underlines the power and efficiency of leveraging pre-trained knowledge in domain-specific tasks.\n",
        "    "
      ],
      "metadata": {
        "id": "_6Qc3zPGcidV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"display: flex; align-items: center; justify-content: center; border-radius: 10px; padding: 20px; background-color:  lavender; font-size: 120%; text-align: center;\">\n",
        "\n",
        "<strong>🎯 For more details or to explore the code further, kindly check out the project's <a href=\"https://github.com/FarzadNekouee/Imbalanced_Garbage_Classification_ResNet50_Scratch_to_Transfer-Learning\">GitHub repository</a> 🎯</strong>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "-fpHFe_xcidV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align=\"left\"><font color=royalblue>Best Regards</font></h2>"
      ],
      "metadata": {
        "id": "QWydHbOOcidV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transfer_resnet50_model.save('waste_classifier2.pt')  # يحفظه كمجلد كامل\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-28T18:30:14.224832Z",
          "iopub.execute_input": "2025-04-28T18:30:14.225564Z",
          "iopub.status.idle": "2025-04-28T18:30:14.229541Z",
          "shell.execute_reply.started": "2025-04-28T18:30:14.225531Z",
          "shell.execute_reply": "2025-04-28T18:30:14.228505Z"
        },
        "id": "XYy7ORzmcidV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_resnet50_model.save('waste_classifier3.h5')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-02T17:06:01.57324Z",
          "iopub.execute_input": "2025-05-02T17:06:01.574209Z",
          "iopub.status.idle": "2025-05-02T17:06:02.188408Z",
          "shell.execute_reply.started": "2025-05-02T17:06:01.574163Z",
          "shell.execute_reply": "2025-05-02T17:06:02.18774Z"
        },
        "id": "ySIGzHwQcidV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "RN4tePibcidW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}